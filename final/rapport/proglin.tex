\subsection{Introduction}
  La programmation linéaire, ou optimisation linéaire, consiste à maximiser
  (resp.\ minimiser) une fonction linéaire sur un polyèdre convexe (dont un cas
  particulier courrant est sous des contraintes linéaires).

\subsection{Problème du sac à dos}
  \subsubsection{Présentation du problème}
    Ce problème paraît simple en apparence: nous avons un ensemble d'objets,
    chaque objet pouvant avoir une masse différente et ayant une certaine
    valeur, et nous voulons remplir un sac à dos de manière à maximiser la
    valeur totale, sans dépasser une certaine masse maximale.

    Résoudre ce genre de problème est utile par exemple en gestion de
    portefeuilles pour trouver le meilleur rapport entre rendement et risque,
    ou en découpe de matériaux, pour minimiser les chutes.

    \paragraph{}
    Ce problème est un problème d'optimisation linéaire, en effet, cela revient
    à résoudre le problème:
    \[ \left\{ \begin{array}{l}
        \max v_i \\
        i \in S \\
        \displaystyle\sum_{j \in S} m_j \leq W
      \end{array} \right.
    \]
    où $S$ est un ensemble de $n$ objets à choisir, $v_i$ la valeur de l'objet
    $i$, $m_i$ sa masse et $W$ la masse maximale autorisée dans le sac.

    \paragraph{}
    Cependant la résolution de ce problème n'est pas simple: déterminer s'il
    est possible de dépasser une valeur minimale sans dépasser le poids maximal
    est un problème NP\nobreakdash-complet.

  \subsubsection{Résolution exacte}
    Ce problème peut être résolu en utilisant la programmation
    dynamique\footnote{Qui consiste à résoudre un problème de taille $n$ à
    partir de la résolution d'un problème de taille $n-1$}. En effet, on peut
    déterminer si un objet $i$ fait parti de l'ensemble des objets à choisir en
    considérant le problème sur l'ensemble $S\backslash\{i\}$ et la masse
    maximale $W-m_i$.
    
    Toutefois, un tel algorithme fonctionne uniquement si les poids des objets
    sont des entiers. De plus sa complexité en temps est en $O(nW)$ et celle en
    mémoire en $O(W)$\footnote{En pratique on pourrait l'utiliser sur des
    masses non-entières en les multipliants, ce qui augmenterait la compléxité
    du même facteur. De plus on peut réduire la compléxité en $O(nW')$ avec
    $W' = \frac W {\mathrm{ppcm}(\text{toutes les masses})}$.}.

    \paragraph{}
    L'algorithme est le suivant:
    \begin{lstlisting}
Entrée : une liste d'objets
         une masse maximale autorisée
Sortie : la valeur maximale qu'il est possible d'atteindre
Précondition : toutes les masses doivent être entières.

ligne_courante = liste composée de masse_max+1 0
ligne_prec     = liste composée de masse_max+1 0

pour chaque objet obj de la liste d'entrée:
    pour m variant de 0 à masse_max:
        if masse(obj) <= m:
            ligne_courrante[m] = max(ligne_prec[m], ligne_prec_line[m-masse(obj)] + prix(obj))

    ligne_prec = ligne_courante

Retourner ligne_courante[masse_max]
    \end{lstlisting}

  \subsubsection{Résolution approchée}
    Un autre algorithme pour résoudre ce problème, dit algorithme glouton,
    consiste simplement à choisir les «~meilleurs~» objets jusqu'à que la masse
    maximale soit dépassée. Le critère déterminant quels sont les meilleurs
    objets pourrait être la masse faible, le prix élevé, ou le rapport
    prix/masse élevé.

    Cet algorithme est beaucoup plus rapide que le précédent (il a une
    complexité en temps de $O(n \log n)$ (pour le tri des objets)) et ne
    nécessite en mémoire que la liste des objets, mais ce n'est qu'un algorithme
    approché. Les résultats obtenus sont cependant très satisfaisant, en effet
    en considérant le ratio \nobreak prix/masse, on obtient des résultats très
    proches de l'optimum (quelques pourcents d'erreur relative en moyenne, mais
    aucune garantie n'est fournie: il peut même fournir la pire solution).

    De plus il peut être utilisé quand les masses ne sont pas entières.

