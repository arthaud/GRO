\subsection{Introduction}
  Un processus stochastique représente l'évolution au cours du temps d'une
  variable aléatoire. Dans cette section, nous étudierons particulièrement les
  processus de Markov, qui sont des processus stochastiques dont l'état futur
  ne dépend pas des états passés.

  Une chaine de Markov est un processus de Markov à temps discret. On
  peut la représenter sous forme d'un graphe, dont les sommets représentent des
  états et les arêtes des transitions d'un état à l'autre.

  \begin{description}
    \item[Irréductible] Une chaine de Markov est irréductible si son graphe est
      fortement connexe.
    \item[Récurrente] Une chaine de Markov irréductible est récurrente si une
      trajectoire typique du système passe infiniment souvent par cet état.
    \item[Apériodique] Une chaine de Markov est apériodique si pour tout sommet $i$,
      \[pgcd(\{ n \geq 1 \mid A^n[i, j] > 0 \}) = 1\] où $A$ est la matrice
      d'adjacence de son graphe.
  \end{description}

\subsection{Colonie de scarabées}
  Le problème consiste, à partir d'un graphe dont les nœuds représentent des
  positions et les arêtes contiennent la probabilité pour un scarabée de passer
  d'une position à l'autre, à calculer les probabilités de présence de chaque
  scarabée au bout de $N$ itérations, selon sa position de départ.

  Pour cela, on représente le graphe sous la forme de matrice d'adjacence $A$, où
  chaque élément de la matrice représente la probabilité de passer d'un nœud à
  un autre.

  Si on met cette matrice à la puissance $N$, elle contiendra les probabilités
  de passer d'un nœud à un autre en exactement $N$ itérations.

  En multipliant cette matrice par un vecteur contenant uniquement des zéros,
  sauf au nœud de départ (on mettra un 1), on peut obtenir la probabilité pour
  le scarabée de se trouver à chaque point, au bout d'exactement $N$ tours.  Si
  cette probabilité est nulle, il est impossible qu'il s'y trouve.

  Pour savoir la probabilité que les deux scarabées se rencontrent en un point
  au bout de $N$ itérations, il suffit de multiplier les probabilités de
  présence de chaque scarabée en ce point. Pour connaitre leur probabilité de se
  rencontrer en n'importe quel point, on peut tout simplement sommer les
  probabilités de rencontre sur chaque point.

  De plus, si on calcule $\displaystyle\lim_{N \to \infty} A^N$ (une telle limite n'existera
  que si la chaine est irréductible, récurrente positive et apériodique, et ça
  ne sera pas toujours le cas!), le produit du vecteur contenant la position de
  départ par cette matrice nous donnera les probabilités pour le scarabée
  d'être en chaque position une fois qu'il aura suffisamment voyagé et que sa
  position de départ n'aura plus d'importance.

  \subsubsection{Chaines de Markov}
    Le problème des scarabées peut aisément être modélisé par des chaines de
    Markov. En effet, nos coléoptères se promènent en temps discret dans leur
    graphe de promenade; de plus, l'état d'un scarabée (autrement dit, sa
    position) ne dépend pas du passé, mais uniquement de l'état présent.

    La matrice de transition (dite aussi matrice stochastique) représente les
    probabilités de passer d'un état aux autres. Par conséquent, la matrice de
    transition à la puissance $n$ représente la probabilité de passer d'un état
    à un autre par un chemin de longueur $n$.

    On constate qu'on se rapproche beaucoup de la matrice décrite précédemment:
    la matrice d'adjacence du graphe de promenade et la matrice de transition
    de notre chaine de Markov sont équivalentes!

  \subsubsection{Temps moyen entre rencontres}
    \paragraph{À partir d'un même point}
      Considérons que les deux scarabées sont sur le même sommet. On peut donc
      calculer la probabilité qu'après $N$ tours, ils finissent à nouveau sur
      le même sommet (en sommant le carré des probabilités que chacun se retrouve
      sur un sommet).

      Notons $U_k = pA^k(pA^k)^\intercal$ la probabilité que les deux scarabées
      se retrouvent sur la même case après $k$ tours.

      Notons $V_k$ la probabilité que les deux scarabées se retrouvent sur la
      même case après $k$ tours, sans s'être déjà rencontrés avant. On a:
        \[V_k = (1 - U_1) \times (1 - U_2) \times \cdots \times (1 - U_{k - 1})
        \times U_k\]

      $V_k$ peut donc se réécrire par récurrence:
        \begin{align*}
          V_1       &= U_1 \\
          V_{k + 1} &= V_k \times \frac{1 - U_k}{U_k}U_{k + 1}
        \end{align*}

      Pour avoir le temps moyen au bout duquel ils vont se rencontrer en
      partant de ce même point, il suffit de prendre l'espérance de cette suite
      $V_k$.

    \paragraph{À partir de deux points différents}
      Dans le cas où les points de départs des scarabées sont différents, on peut
      appliquer le même principe.

      Par contre, on ne peut pas supposer $U_k \neq 0$. %todo: pourquoi on pouvait avant?
      On peut introduire une suite $W_k$: %todo: pourquoi on a pas fait ça avant?
      \begin{align*}
        W_0 &= 1 \\
        W_k &= W_{k-1} \times (1 - U_k)
      \end{align*}

      On a donc:
      \begin{align*}
        V_1  &= U_1 \\
        V_k &= W_{k-1} \times U_k
      \end{align*}

      Pour avoir un temps moyen de rencontre global, on fait la moyenne du temps
      de rencontre pour chaque position initiale possible.

  \subsubsection{Exemple}
    Partons du graphe suivant:
    \begin{center}
      \begin{tikzpicture}[->, >=stealth', shorten >=1pt, auto]
        \node[draw, circle] (1) at (0, 0) {1};
        \node[draw, circle] (2) at (-2.8, 4) {2};
        \node[draw, circle] (3) at (2.8, 4) {3};

        \path (2) edge [bend left=10, -triangle 90] node {$\frac 1 3$} (1);
        \path (1) edge [bend left=10, -triangle 90] node {$\frac 1 4$} (2);
        \path (3) edge [bend left=10, -triangle 90] node {$\frac 1 2$} (1);
        \path (1) edge [bend left=10, -triangle 90] node {$\frac 3 4$} (3);
        \path (3) edge [-triangle 90] node {$\frac 1 2$} (2);
        \path (2) edge [-triangle 90] node {} (3);
      \end{tikzpicture}
    \end{center}

    La matrice d'adjacence de ce graphe est:
      \[A = \left(\begin{array}{ccc}
        0 & \frac 1 4 & \frac 3 4 \\
        \frac 1 3 & \frac 1 6 & \frac 1 2 \\
        \frac 1 2 & \frac 1 2 & 0
      \end{array}\right)\]

    Si on veut connaitre la probabilité qu'un scarabée se trouve au sommet 2 en
    partant du sommet 1 sur 10 tours, on calcule:
      \[
        \left(\begin{array}{ccc}
          1 & 0 & 0
        \end{array}\right)
        \times
        \left(\begin{array}{ccc}
          0 & \frac 1 4 & \frac 3 4 \\
          \frac 1 3 & \frac 1 6 & \frac 1 2 \\
          \frac 1 2 & \frac 1 2 & 0
        \end{array}\right)^{10}
        \approx
        \left(\begin{array}{ccc}
          0.30188 & 0.32244 & 0.37568
        \end{array}\right)
      \]

    La probabilité voulue est donc $0.32244$.

    \paragraph{}
    De plus, on remarque que $A^n$ converge vers
      \[
        \left(\begin{array}{ccc}
          0.29787 & 0.31915 & 0.38298 \\
          0.29787 & 0.31915 & 0.38298 \\
          0.29787 & 0.31915 & 0.38298
        \end{array}\right)
      \]
    lorsque $n \to +\infty$, donc quelle que soit la position de départ du
    scarabée, après un nombre suffisant de tours, la probabilité qu'il soit sur
    le sommet 2 est $0.31915$.

    \paragraph{}
    En calculant l'espérance de la suite $V_k$, on a le temps moyen entre chaque
    rencontre:

    \begin{center}
      \begin{tabular}{|c|c|}
        \hline
        Départ & Temps moyen entre chaque rencontre \\\hline
        1      & 1.991808 \\\hline
        2      & 2.810620 \\\hline
        3      & 2.272463 \\\hline
      \end{tabular}
    \end{center}

\subsection{Théorie des files d'attente}
  Une file d'attente est un système ayant une entrée par laquelle arrivent des
  tâches, ou clients, qui attendent leur tour avant d'être traitées une par une pour en
  sortir.

  Elles sont utilisées pour l'étude de beaucoup de systèmes: attentes de
  clients à des guichets, trafic routier, traitement des tâches par un
  serveur, etc.

  \paragraph{}
  Les files sont étudiées en fonction de la loi qui gère l'entrée, la loi qui
  gère la sortie et le nombre de ``serveurs'' qui traitent les clients.

  La loi de Little est cependant un résultat général:
    \[N = \lambda T_s\]
  où $N$ est le nombre moyen de clients dans le système, $\lambda$ la fréquence
  moyenne d'entrée et $T_s$ le temps moyen passé dans le système.

  \subsubsection{Cas M/M/1}
    On considère une file d'attente où la loi d'entrée suit une loi de Poisson
    de paramètre $\lambda$ ($\lambda$ est donc le nombre moyen d'arrivées par
    unité de temps) et où le temps de service suit une loi exponentielle de
    paramètre $\mu$ ($\frac 1 \mu$ est donc le temps moyen de traitement, sans
    compter l'attente dans la file).

    On dit que ce genre de file d'attente est de type $M/M/1$ selon les
    notations de Kendall.

    Dans ce cas, le nombre moyen d'arrivées pendant le temps de service, appelé
    trafic offert, est $\rho = \frac \lambda \mu$. Le système converge alors si
    et seulement si $\rho < 1$.
    
    \paragraph{}
    La file peut être représentée comme une chaine de Markov où chaque état $i$
    représente la probabilité qu'il y ait $i$ voitures dans le système (voir
    figure~\ref{fig:markov1}).

    \begin{figure}[h]
      \centering
      \begin{tikzpicture}[->,shorten >=1pt,auto,node distance=2cm,semithick]
        \tikzstyle{every state}=[fill=white,draw=black,text=black,minimum size=1.1cm]

        \node[state] (A) {0};
        \node[state] (B) [right of=A] {$1$};
        \node[state] (C) [right of=B] {$2$};
        \node[state] (D) [right of=C] {$3$};
        \node[minimum size=1cm] (E) [right of=D] {$\cdots$};

        \path (A) edge [bend left] node {$\lambda$} (B);
        \path (B) edge [bend left] node {$\mu$} (A);
        \path (B) edge [bend left] node {$\lambda$} (C);
        \path (C) edge [bend left] node {$\mu$} (B);
        \path (C) edge [bend left] node {$\lambda$} (D);
        \path (D) edge [bend left] node {$\mu$} (C);
        \path (D) edge [bend left] node {$\lambda$} (E);
        \path (E) edge [bend left] node {$\mu$} (D);
      \end{tikzpicture}
      \caption{Représentation d'une file M/M/1 comme une chaine de Markov
        \cite{procstochs_cc}}
      \label{fig:markov1}
    \end{figure}

    Ces états sont liés en régime permanent par les équations:
      \[
        \left\{\begin{aligned}
          \lambda p_0 & = \mu p_1 \\
          \lambda p_1 & = \mu p_2 \\
          & \cdots \\
          \lambda p_n & = \mu p_{n+1} \\
          & \cdots 
        \end{aligned}\right.
      \]
    et
      \[
        \sum_{i=0}^{+\infty} p_n = 1
      \]

    D'où $p_n = \left(\frac \lambda \mu\right)^n p_0 =
     \left(\frac \lambda \mu\right)^n \left(1-\frac \lambda \mu\right) =
     \rho^n (1-\rho)$ (d'où la condition $\rho < 1$).

   Le nombre moyen de clients dans le système est donc:
     \[ N = \sum_{i=0}^n np_n = \frac \rho {1-\rho} \]

   D'après la loi de Little, le temps moyen passé dans le système est donc:
     \[
       T_s = \frac 1 \lambda \frac \rho {1-\rho}
           = \rho \frac \lambda {\mu-\lambda}
     \]

  \subsubsection{Cas M/M/S}
    Une généralisation du cas précédent sont les files de type $M/M/S$, où $S$
    dénote le nombre de serveurs. Les lois d'entrée et sortie restent les mêmes.

    Ces files peuvent aussi être représentées avec les chaines de Markov (voir
    figure~\ref{fig:markov2}).

    \begin{figure}[h]
      \centering
      \makebox[\textwidth]{\begin{tikzpicture}
        [->,shorten >=1pt,auto,node distance=2cm,semithick]
        \tikzstyle{every state}=[fill=white,draw=black,text=black,minimum size=1.1cm]

        \node[state] (A) {0};
        \node[state] (B) [right of=A] {$1$};
        \node[state] (C) [right of=B] {$2$};
        \node[state] (D) [right of=C] {$3$};
        \node[minimum size=1cm] (E) [right of=D] {$\cdots$};
        \node[state] (F) [right of=E] {$S-1$};
        \node[state] (G) [right of=F] {$\phantom{+}S\phantom{+}$};
        \node[state] (H) [right of=G] {$S+1$};
        \node[minimum size=1cm] (I) [right of=H] {$\cdots$};

        \path (A) edge [bend left] node {$\lambda$} (B);
        \path (B) edge [bend left] node {$\mu$} (A);
        \path (B) edge [bend left] node {$\lambda$} (C);
        \path (C) edge [bend left] node {$2\mu$} (B);
        \path (C) edge [bend left] node {$\lambda$} (D);
        \path (D) edge [bend left] node {$3\mu$} (C);
        \path (D) edge [bend left] node {$\lambda$} (E);
        \path (E) edge [bend left] node {$4\mu$} (D);
        \path (E) edge [bend left] node {$\lambda$} (F);
        \path (F) edge [bend left] node {$(S-1)\mu$} (E);
        \path (F) edge [bend left] node {$\lambda$} (G);
        \path (G) edge [bend left] node {$S\mu$} (F);
        \path (G) edge [bend left] node {$\lambda$} (H);
        \path (H) edge [bend left] node {$S\mu$} (G);
        \path (H) edge [bend left] node {$\lambda$} (I);
        \path (I) edge [bend left] node {$S\mu$} (H);
      \end{tikzpicture}}
      \caption{Représentation d'une file M/M/S comme une chaine de Markov
        \cite{procstochs_cc}}
      \label{fig:markov2}
    \end{figure}

    L'étude de ces chaines est plus compliquée car les états ne sont plus liés
    par la même équation:
      \[
        \left\{\begin{aligned}
          \lambda p_0 & = \phantom{2\times~}\mu p_1 \\
          \lambda p_1 & = 2\times\mu p_2 \\
          & \cdots \\
          \lambda p_{S-2} & = (S-1)\times\mu p_{S-1} \\
          \lambda p_{S-1} & = S\times\mu p_S \\
          \lambda p_S & = S\times\mu p_{S+1} \\
          \lambda p_{S+1} & = S\times\mu p_{S+2} \\
          & \cdots 
        \end{aligned}\right.
      \]

    On peut montrer que le système est en équilibre si et seulement si
    $\rho = \frac \lambda {S\mu} < 1$. Le nombre moyen de clients et temps
    moyen dans le système sont par contre beaucoup moins intuitifs:
    \[
      \begin{aligned}
        N   &= \rho \left(1 + \frac{P_a}{S-\rho}\right) \\
        T_s &= \frac{1}{\mu} \left(1 + \frac{P_a}{S-\rho}\right)
      \end{aligned}
    \]
    où $\displaystyle P_a = P_0 \frac{\rho^S}{(S-1)!(S-\rho)}$ est la
    probabilité d'attendre et $\displaystyle P_0 = \frac{1}{\sum_{k=0}^{S-1}
    \frac{\rho^k}{k!} + \frac {\rho^S}{S!} \frac {1}{1-\rho/S} }$ est la
    probabilité que le système soit vide.

    On remarque qu'on retrouve bien les mêmes résultats que précédemment pour
    $S=1$.

\subsection{Conclusion}
  Les processus stochastiques nous montrent une fois de plus l'utilité des
  graphes. %todo

